{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "# 词表\n",
    "class Vocab:\n",
    "    def __init__(self, tokens=None):\n",
    "        self.idx_to_token = list()\n",
    "        self.token_to_idx = dict()\n",
    "\n",
    "        if tokens is not None:\n",
    "            if \"<unk>\" not in tokens:\n",
    "                tokens = tokens + [\"<unk>\"]\n",
    "            for token in tokens:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "            self.unk = self.token_to_idx['<unk>']\n",
    "\n",
    "    @classmethod\n",
    "    def build(cls, text, min_freq=1, reserved_tokens=None):\n",
    "        token_freqs = defaultdict(int)\n",
    "        for sentence in text:\n",
    "            for token in sentence:\n",
    "                token_freqs[token] += 1\n",
    "        uniq_tokens = [\"<unk>\"] + (reserved_tokens if reserved_tokens else [])\n",
    "        uniq_tokens += [token for token, freq in token_freqs.items() \\\n",
    "                        if freq >= min_freq and token != \"<unk>\"]\n",
    "        return cls(uniq_tokens)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return self.token_to_idx.get(token, self.unk)\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        return [self[token] for token in tokens]\n",
    "\n",
    "    def convert_ids_to_tokens(self, indices):\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "\n",
    "def save_vocab(vocab, path):\n",
    "    with open(path, 'w') as writer:\n",
    "        writer.write(\"\\n\".join(vocab.idx_to_token))\n",
    "\n",
    "\n",
    "def read_vocab(path):\n",
    "    with open(path, 'r') as f:\n",
    "        tokens = f.read().split('\\n')\n",
    "    return Vocab(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 获得数据集\n",
    "def get_loader(dataset, batch_size, shuffle=True):\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=dataset.collate_fn,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELMo模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import codecs\n",
    "\n",
    "BOS_TOKEN = \"<bos>\"\n",
    "EOS_TOKEN = \"<eos>\"\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "BOW_TOKEN = \"<bow>\"\n",
    "EOW_TOKEN = \"<eow>\"\n",
    "\n",
    "def load_corpus(path, max_tok_len=None, max_seq_len=None):\n",
    "    \"\"\"\n",
    "    从生文本语料中加载数据并构建词表\n",
    "    max_tok_len：词的长度（字符数目）上限\n",
    "    max_seq_len：序列长度（词数）上限\n",
    "    \"\"\"\n",
    "    text = []\n",
    "    # 字符集，首先加入预定义特殊标记，包含句首、句尾、补齐标记、词首和词尾\n",
    "    charset = {BOS_TOKEN, EOS_TOKEN, PAD_TOKEN, BOW_TOKEN, EOW_TOKEN}\n",
    "    print(f\"Loading corpus from {path}\")\n",
    "    with codecs.open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in tqdm(f):\n",
    "            tokens = line.rstrip().split(\" \")\n",
    "            # 截断长序列\n",
    "            if max_seq_len is not None and len(tokens) + 2 > max_seq_len:\n",
    "                tokens = line[:max_seq_len-2]\n",
    "            sent = [BOS_TOKEN]\n",
    "            for token in tokens:\n",
    "                # 截断字符数目过多的词\n",
    "                if max_tok_len is not None and len(token) + 2 > max_tok_len:\n",
    "                    token = token[:max_tok_len-2]\n",
    "                sent.append(token)\n",
    "                for ch in token:\n",
    "                    charset.add(ch)\n",
    "            sent.append(EOS_TOKEN)\n",
    "            text.append(sent)\n",
    "\n",
    "    # Build word and character vocabulary\n",
    "    print(\"Building word-level vocabulary\")\n",
    "    vocab_w = Vocab.build(\n",
    "        text,\n",
    "        min_freq=2,\n",
    "        reserved_tokens=[PAD_TOKEN, BOS_TOKEN, EOS_TOKEN]\n",
    "    )\n",
    "    print(\"Building char-level vocabulary\")\n",
    "    vocab_c = Vocab(tokens=list(charset))\n",
    "\n",
    "    # Construct corpus using word_voab and char_vocab\n",
    "    corpus_w = [vocab_w.convert_tokens_to_ids(sent) for sent in text]\n",
    "    corpus_c = []\n",
    "    bow = vocab_c[BOW_TOKEN]\n",
    "    eow = vocab_c[EOW_TOKEN]\n",
    "    for i, sent in enumerate(text):\n",
    "        sent_c = []\n",
    "        for token in sent:\n",
    "            if token == BOS_TOKEN or token == EOS_TOKEN:\n",
    "                token_c = [bow, vocab_c[token], eow]\n",
    "            else:\n",
    "                token_c = [bow] + vocab_c.convert_tokens_to_ids(token) + [eow]\n",
    "            sent_c.append(token_c)\n",
    "        assert len(sent_c) == len(corpus_w[i])\n",
    "        corpus_c.append(sent_c)\n",
    "\n",
    "    assert len(corpus_w) == len(corpus_c)\n",
    "    return corpus_w, corpus_c, vocab_w, vocab_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "## 数据类：这个函数写的太工整了！\n",
    "class BiLMDataset(Dataset):\n",
    "    def __init__(self, corpus_w, corpus_c, vocab_w, vocab_c):\n",
    "        super(BiLMDataset, self).__init__()\n",
    "        self.pad_w = vocab_w[PAD_TOKEN]\n",
    "        self.pad_c = vocab_c[PAD_TOKEN]\n",
    "\n",
    "        self.data = []\n",
    "        for sent_w, sent_c in tqdm(zip(corpus_w, corpus_c)):\n",
    "            self.data.append((sent_w, sent_c))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "\n",
    "    def collate_fn(self, examples):\n",
    "        # lengths: batch_size\n",
    "        # 当前批次中各样本序列的长度\n",
    "        seq_lens = torch.LongTensor([len(ex[0]) for ex in examples])\n",
    "\n",
    "        # inputs_w\n",
    "        # 词级别输入：batch_size * max_seq_len\n",
    "        inputs_w = [torch.tensor(ex[0]) for ex in examples]\n",
    "        # 对batch内的样本进行长度补齐\n",
    "        inputs_w = pad_sequence(inputs_w, batch_first=True, padding_value=self.pad_w)\n",
    "        \n",
    "        # 计算当前批次中的最大序列长度以及单词的最大字符数目\n",
    "        batch_size, max_seq_len = inputs_w.shape\n",
    "        max_tok_len = max([max([len(tok) for tok in ex[1]]) for ex in examples])\n",
    "\n",
    "        # inputs_c: batch_size * max_seq_len * max_tok_len\n",
    "        inputs_c = torch.LongTensor(batch_size, max_seq_len, max_tok_len).fill_(self.pad_c) # 使用指定的值（self.pad_c）填充整个张量\n",
    "        for i, (sent_w, sent_c) in enumerate(examples):\n",
    "            for j, tok in enumerate(sent_c):\n",
    "                inputs_c[i][j][:len(tok)] = torch.LongTensor(tok)\n",
    "\n",
    "        # fw_input_indexes, bw_input_indexes = [], []\n",
    "        # 前向、后向语言模型的目标输出序列\n",
    "        targets_fw = torch.LongTensor(inputs_w.shape).fill_(self.pad_w)\n",
    "        targets_bw = torch.LongTensor(inputs_w.shape).fill_(self.pad_w)\n",
    "        for i, (sent_w, sent_c) in enumerate(examples):\n",
    "            targets_fw[i][:len(sent_w)-1] = torch.LongTensor(sent_w[1:])\n",
    "            targets_bw[i][1:len(sent_w)] = torch.LongTensor(sent_w[:len(sent_w)-1])\n",
    "\n",
    "        return inputs_w, inputs_c, seq_lens, targets_fw, targets_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## 输入表示层最后的Highway层\n",
    "class Highway(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers, activation=F.relu):\n",
    "        super(Highway, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.layers = torch.nn.ModuleList(\n",
    "            [nn.Linear(input_dim, input_dim * 2) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.activation = activation\n",
    "        for layer in self.layers:\n",
    "            # set bias in the gates to be positive\n",
    "            # such that the highway layer will be biased towards the input part\n",
    "            layer.bias[input_dim:].data.fill_(1) # 将偏置的一部分初始化为1，这将使门控机制在开始时更倾向于使用输入信号\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        curr_inputs = inputs\n",
    "        for layer in self.layers:\n",
    "            projected_inputs = layer(curr_inputs)\n",
    "            hidden = self.activation(projected_inputs[:, 0:self.input_dim])\n",
    "            gate = torch.sigmoid(projected_inputs[:, self.input_dim:]) # 对投影后的输出的另一部分进行Sigmoid激活，得到门控信号\n",
    "            curr_inputs = gate * curr_inputs + (1 - gate) * hidden # 根据门控信号和残差信号的权重，组合得到当前层的输出，作为下一层的输入\n",
    "        return curr_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于字符卷积的词表示层\n",
    "class ConvTokenEmbedder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_c,\n",
    "        char_embedding_dim,\n",
    "        char_conv_filters,\n",
    "        num_highways,\n",
    "        output_dim,\n",
    "        pad=\"<pad>\"\n",
    "    ):\n",
    "        super(ConvTokenEmbedder, self).__init__()\n",
    "        self.vocab_c = vocab_c\n",
    "\n",
    "        self.char_embeddings = nn.Embedding(\n",
    "            len(vocab_c),\n",
    "            char_embedding_dim,\n",
    "            padding_idx=vocab_c[pad]\n",
    "        )\n",
    "        self.char_embeddings.weight.data.uniform_(-0.25, 0.25)\n",
    "\n",
    "        self.convolutions = nn.ModuleList()\n",
    "        for kernel_size, out_channels in char_conv_filters:\n",
    "            conv = torch.nn.Conv1d(\n",
    "                in_channels=char_embedding_dim,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                bias=True\n",
    "            )\n",
    "            self.convolutions.append(conv)\n",
    "\n",
    "        self.num_filters = sum(f[1] for f in char_conv_filters)\n",
    "        self.num_highways = num_highways\n",
    "        self.highways = Highway(self.num_filters, self.num_highways, activation=F.relu)\n",
    "\n",
    "        self.projection = nn.Linear(self.num_filters, output_dim, bias=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, seq_len, token_len = inputs.shape\n",
    "        inputs = inputs.view(batch_size * seq_len, -1)\n",
    "        char_embeds = self.char_embeddings(inputs)\n",
    "        char_embeds = char_embeds.transpose(1, 2)\n",
    "\n",
    "        conv_hiddens = []\n",
    "        for i in range(len(self.convolutions)):\n",
    "            conv_hidden = self.convolutions[i](char_embeds)\n",
    "            conv_hidden, _ = torch.max(conv_hidden, dim=-1)\n",
    "            conv_hidden = F.relu(conv_hidden)\n",
    "            conv_hiddens.append(conv_hidden)\n",
    "\n",
    "        token_embeds = torch.cat(conv_hiddens, dim=-1)\n",
    "        token_embeds = self.highways(token_embeds)\n",
    "        token_embeds = self.projection(token_embeds)\n",
    "        token_embeds = token_embeds.view(batch_size, seq_len, -1)\n",
    "\n",
    "        return token_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "## 双向lstm编码器\n",
    "class ELMoLstmEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        num_layers,\n",
    "        dropout_prob=0.0\n",
    "    ):\n",
    "        super(ELMoLstmEncoder, self).__init__()\n",
    "\n",
    "        # set projection_dim==input_dim for ELMo usage\n",
    "        # 保证lstm各中间层及输出层具有和输入表示层相同的维度\n",
    "        self.projection_dim = input_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # 前向lstm（多层）\n",
    "        self.forward_layers = nn.ModuleList()\n",
    "        # 后向lstm列表\n",
    "        self.backward_layers = nn.ModuleList()\n",
    "        # 前向lstm投射层\n",
    "        self.forward_projections = nn.ModuleList()\n",
    "        # 后向lstm投射层\n",
    "        self.backward_projections = nn.ModuleList()\n",
    "\n",
    "        lstm_input_dim = input_dim\n",
    "        for _ in range(num_layers):\n",
    "            # 单向前向lstm以及投射层\n",
    "            forward_layer = nn.LSTM(\n",
    "                lstm_input_dim,\n",
    "                hidden_dim,\n",
    "                num_layers=1,\n",
    "                batch_first=True\n",
    "            )\n",
    "            forward_projection = nn.Linear(hidden_dim, self.projection_dim, bias=True)\n",
    "\n",
    "            # 单向后向lstm以及投射层\n",
    "            backward_layer = nn.LSTM(\n",
    "                lstm_input_dim,\n",
    "                hidden_dim,\n",
    "                num_layers=1,\n",
    "                batch_first=True\n",
    "            )\n",
    "            backward_projection = nn.Linear(hidden_dim, self.projection_dim, bias=True)\n",
    "\n",
    "            lstm_input_dim = self.projection_dim\n",
    "\n",
    "            self.forward_layers.append(forward_layer)\n",
    "            self.forward_projections.append(forward_projection)\n",
    "            self.backward_layers.append(backward_layer)\n",
    "            self.backward_projections.append(backward_projection)\n",
    "\n",
    "    def forward(self, inputs, lengths):\n",
    "        batch_size, seq_len, input_dim = inputs.shape\n",
    "\n",
    "        # 根据前向输入批次中序列长度信息，构建后向输入批次\n",
    "        rev_idx = torch.arange(seq_len).unsqueeze(0).repeat(batch_size, 1)\n",
    "        for i in range(lengths.shape[0]):\n",
    "            rev_idx[i,:lengths[i]] = torch.arange(lengths[i]-1, -1, -1)\n",
    "        rev_idx = rev_idx.unsqueeze(2).expand_as(inputs)\n",
    "        rev_idx = rev_idx.to(inputs.device)\n",
    "        rev_inputs = inputs.gather(1, rev_idx)\n",
    "\n",
    "        # 前向、后向lstm输入\n",
    "        forward_inputs, backward_inputs = inputs, rev_inputs\n",
    "        stacked_forward_states, stacked_backward_states = [], []\n",
    "        \n",
    "        # 用于保存每一层前向、后向隐含层状态\n",
    "        for layer_index in range(self.num_layers):\n",
    "            # Transfer `lengths` to CPU to be compatible with latest PyTorch versions.\n",
    "            packed_forward_inputs = pack_padded_sequence(\n",
    "                forward_inputs, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            packed_backward_inputs = pack_padded_sequence(\n",
    "                backward_inputs, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "            # forward\n",
    "            forward_layer = self.forward_layers[layer_index]\n",
    "            packed_forward, _ = forward_layer(packed_forward_inputs)\n",
    "            forward = pad_packed_sequence(packed_forward, batch_first=True)[0]\n",
    "            forward = self.forward_projections[layer_index](forward)\n",
    "            stacked_forward_states.append(forward)\n",
    "\n",
    "            # backward\n",
    "            backward_layer = self.backward_layers[layer_index]\n",
    "            packed_backward, _ = backward_layer(packed_backward_inputs)\n",
    "            backward = pad_packed_sequence(packed_backward, batch_first=True)[0]\n",
    "            backward = self.backward_projections[layer_index](backward)\n",
    "            # convert back to original sequence order using rev_idx\n",
    "            # 恢复至序列的原始顺序\n",
    "            stacked_backward_states.append(backward.gather(1, rev_idx))\n",
    "\n",
    "            forward_inputs, backward_inputs = forward, backward\n",
    "\n",
    "        # stacked_forward_states: [batch_size, seq_len, projection_dim] * num_layers\n",
    "        # stacked_backward_states: [batch_size, seq_len, projection_dim] * num_layers\n",
    "        return stacked_forward_states, stacked_backward_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class BiLM(nn.Module):\n",
    "    \"\"\"\n",
    "    多层双向语言模型。\n",
    "    \"\"\"\n",
    "    def __init__(self, configs, vocab_w, vocab_c):\n",
    "        super(BiLM, self).__init__()\n",
    "        self.dropout_prob = configs['dropout_prob']\n",
    "        self.num_classes = len(vocab_w)\n",
    "\n",
    "        self.token_embedder = ConvTokenEmbedder(\n",
    "            vocab_c,\n",
    "            configs['char_embedding_dim'],\n",
    "            configs['char_conv_filters'],\n",
    "            configs['num_highways'],\n",
    "            configs['projection_dim']\n",
    "        )\n",
    "\n",
    "        self.encoder = ELMoLstmEncoder(\n",
    "            configs['projection_dim'],\n",
    "            configs['hidden_dim'],\n",
    "            configs['num_layers']\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(configs['projection_dim'], self.num_classes)\n",
    "\n",
    "    def forward(self, inputs, lengths):\n",
    "        token_embeds = self.token_embedder(inputs)\n",
    "        token_embeds = F.dropout(token_embeds, self.dropout_prob)\n",
    "        forward, backward = self.encoder(token_embeds, lengths)\n",
    "\n",
    "        return self.classifier(forward[-1]), self.classifier(backward[-1])\n",
    "\n",
    "    def save_pretrained(self, path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        torch.save(self.token_embedder.state_dict(), os.path.join(path, 'token_embedder.pth'))\n",
    "        torch.save(self.encoder.state_dict(), os.path.join(path, 'encoder.pth'))\n",
    "        torch.save(self.classifier.state_dict(), os.path.join(path, 'classifier.pth'))\n",
    "\n",
    "    def load_pretrained(self, path):\n",
    "        self.token_embedder.load_state_dict(torch.load(os.path.join(path, 'token_embedder.pth')))\n",
    "        self.encoder.load_state_dict(torch.load(os.path.join(path, 'encoder.pth')))\n",
    "        self.classifier.load_state_dict(torch.load(os.path.join(path, 'classifier.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "## 训练\n",
    "\n",
    "configs = {\n",
    "    'max_tok_len': 50,\n",
    "    'train_file': './train.txt', # path to your training file, line-by-line and tokenized\n",
    "    'model_path': './elmo_bilm',\n",
    "    'char_embedding_dim': 50,\n",
    "    'char_conv_filters': [[1, 32], [2, 32], [3, 64], [4, 128], [5, 256], [6, 512], [7, 1024]],\n",
    "    'num_highways': 2,\n",
    "    'projection_dim': 512,\n",
    "    'hidden_dim': 4096,\n",
    "    'num_layers': 2,\n",
    "    'batch_size': 32,\n",
    "    'dropout_prob': 0.1,\n",
    "    'learning_rate': 0.0004,\n",
    "    'clip_grad': 5,\n",
    "    'num_epoch': 10\n",
    "}\n",
    "\n",
    "# 构建模型和加载器\n",
    "corpus_w, corpus_c, vocab_w, vocab_c = load_corpus(configs['train_file'])\n",
    "train_data = BiLMDataset(corpus_w, corpus_c, vocab_w, vocab_c)\n",
    "train_loader = get_loader(train_data, configs['batch_size'])\n",
    "\n",
    "# 交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    ignore_index=vocab_w[PAD_TOKEN], # 忽略所有PAD_TOKEN处的预测损失\n",
    "    reduction=\"sum\"\n",
    ")\n",
    "print(\"Building BiLM model\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BiLM(configs, vocab_w, vocab_c)\n",
    "print(model)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda x: x.requires_grad, model.parameters()),\n",
    "    lr=configs['learning_rate']\n",
    ")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(configs['num_epoch']):\n",
    "    total_loss = 0\n",
    "    # 有效预测位置的数量\n",
    "    total_tags = 0 # number of valid predictions\n",
    "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "        batch = [x.to(device) for x in batch]\n",
    "        inputs_w, inputs_c, seq_lens, targets_fw, targets_bw = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs_fw, outputs_bw = model(inputs_c, seq_lens)\n",
    "        loss_fw = criterion(\n",
    "            outputs_fw.view(-1, outputs_fw.shape[-1]),\n",
    "            targets_fw.view(-1)\n",
    "        )\n",
    "        loss_bw = criterion(\n",
    "            outputs_bw.view(-1, outputs_bw.shape[-1]),\n",
    "            targets_bw.view(-1)\n",
    "        )\n",
    "        loss = (loss_fw + loss_bw) / 2.0\n",
    "        loss.backward()\n",
    "        \n",
    "        # 梯度剪裁\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), configs['clip_grad']) # 梯度剪裁的主要思想是当梯度的范数（即梯度向量的长度）超过预定的阈值时，将梯度向量进行缩放，使其范数不超过阈值，从而避免梯度爆炸。\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss_fw.item()\n",
    "        total_tags += seq_lens.sum().item()\n",
    "\n",
    "    # 以前向语言模型的困惑度（PPL）作为模型当前性能指标\n",
    "    train_ppl = np.exp(total_loss / total_tags)\n",
    "    print(f\"Train PPL: {train_ppl:.2f}\")\n",
    "\n",
    "# save BiLM encoders\n",
    "model.save_pretrained(configs['model_path'])\n",
    "# save configs\n",
    "json.dump(configs, open(os.path.join(configs['model_path'], 'configs.json'), \"w\"))\n",
    "# save vocabularies\n",
    "save_vocab(vocab_w, os.path.join(configs['model_path'], 'word.dic'))\n",
    "save_vocab(vocab_c, os.path.join(configs['model_path'], 'char.dic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 封装\n",
    "class ELMo(nn.Module):\n",
    "    def __init__(self, model_dir):\n",
    "        super(ELMo, self).__init__()\n",
    "        \n",
    "        # 加载配置文件\n",
    "        self.configs = json.load(open(os.path.join(model_dir, 'cofigs.json')))\n",
    "\n",
    "        # 读取词表，此处只需要读取字符级词表\n",
    "        self.vocab_c = read_vocab(os.path.join(model_dir, 'char.dic'))\n",
    "\n",
    "        # 词表示编码器\n",
    "        self.token_embedder = ConvTokenEmbedder(\n",
    "            vocab_c,\n",
    "            configs['char_embedding_dim'],\n",
    "            configs['char_conv_filters'],\n",
    "            configs['num_highways'],\n",
    "            configs['projection_dim']\n",
    "        )\n",
    "\n",
    "        # ELMo lstm编码器\n",
    "        self.encoder = ELMoLstmEncoder(\n",
    "            configs['projection_dim'],\n",
    "            configs['hidden_dim'],\n",
    "            configs['num_layers']\n",
    "        )\n",
    "\n",
    "        self.output_dim = self.configs['projection_dim']\n",
    "\n",
    "        self.load_pretrained(model_dir)\n",
    "    \n",
    "    def load_pretrained(self, path):\n",
    "\n",
    "        # 加载词表示编码器\n",
    "        self.token_embedder.load_state_dict(torch.load(os.path.join(path, \"token_embedder.pth\")))\n",
    "        \n",
    "        # 加载编码器\n",
    "        self.encoder.load_state_dict(torch.load(os.path.join(path, \"encoder.pth\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用哈工大的EMLo模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "options_file=\"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options. json\"\n",
    "weights_file=\"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights. hdf5\"\n",
    "elmo = Elmo(options_file, weights_file, num_output_representations=1,dropout=0)\n",
    "\n",
    "sentences = [['i', 'love', 'elmo'], ['hello', 'elmo']]\n",
    "character_ids = batch_to_ids(sentences)\n",
    "# 2 * 3 * 50\n",
    "embeddings = elmo(character_ids)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 作为下游任务的特征\n",
    "\n",
    "class BowDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "\n",
    "def collate_fn(examples):\n",
    "    inputs = [torch.tensor(ex[0]) for ex in examples]\n",
    "    targets = torch.tensor([ex[1] for ex in examples], dtype=torch.long)\n",
    "    offsets = [0] + [i.shape[0] for i in inputs]\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    inputs = torch.cat(inputs)\n",
    "    return inputs, offsets, targets\n",
    "\n",
    "def load_sentence_polarity():\n",
    "    from nltk.corpus import sentence_polarity\n",
    "\n",
    "    vocab = Vocab.build(sentence_polarity.sents())\n",
    "\n",
    "    train_data = [(vocab.convert_tokens_to_ids(sentence), 0)\n",
    "                  for sentence in sentence_polarity.sents(categories='pos')[:4000]] \\\n",
    "        + [(vocab.convert_tokens_to_ids(sentence), 1)\n",
    "            for sentence in sentence_polarity.sents(categories='neg')[:4000]]\n",
    "\n",
    "    test_data = [(vocab.convert_tokens_to_ids(sentence), 0)\n",
    "                 for sentence in sentence_polarity.sents(categories='pos')[4000:]] \\\n",
    "        + [(vocab.convert_tokens_to_ids(sentence), 1)\n",
    "            for sentence in sentence_polarity.sents(categories='neg')[4000:]]\n",
    "\n",
    "    return train_data, test_data, vocab\n",
    "\n",
    "class ELMoMLP(nn.Module):\n",
    "    def __init__(self, elmo, hidden_dim, num_class):\n",
    "        super(ELMoMLP, self).__init__()\n",
    "\n",
    "        # 使用AllenNLP\n",
    "        self.elmo = elmo\n",
    "        # 隐含层\n",
    "        self.fc1 = nn.Linear(self.elmo.get_output_dim(), hidden_dim)\n",
    "        # 输出层\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_class)\n",
    "        self.activate = F.relu\n",
    "    \n",
    "    def forward(self, inputs, lengths):\n",
    "        elmo_output = self.elmo(inputs)\n",
    "        embeds = elmo_output['elmo_representations'][0]\n",
    "        mask = elmo_output['mask']\n",
    "\n",
    "        # 将每个序列中词的elmo向量均值作为该序列的向量表示，作为MLP的输入\n",
    "        embeds = torch.sum(embeds * mask.unsqueeze(2), dim=1) / lengths.unsqueeze(1)\n",
    "        hidden = self.activate(self.fc1(embeds))\n",
    "        output = self.fc2(hidden)\n",
    "        log_probs = F.log_softmax(output, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "# tqdm是一个Python模块，能以进度条的方式显示迭代的进度\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 超参数设置\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_class = 2\n",
    "batch_size = 32\n",
    "num_epoch = 10\n",
    "\n",
    "# 加载数据\n",
    "train_data, test_data, vocab = load_sentence_polarity()\n",
    "train_dataset = BowDataset(train_data)\n",
    "test_dataset = BowDataset(test_data)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "# 加载模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ELMoMLP(elmo, hidden_dim, num_class)\n",
    "model.to(device) # 将模型加载到CPU或GPU设备\n",
    "\n",
    "#训练过程\n",
    "nll_loss = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # 使用Adam优化器\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_data_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "        inputs, offsets, targets = [x.to(device) for x in batch]\n",
    "        log_probs = model(inputs, offsets)\n",
    "        loss = nll_loss(log_probs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Loss: {total_loss:.2f}\")\n",
    "\n",
    "# 测试过程\n",
    "acc = 0\n",
    "for batch in tqdm(test_data_loader, desc=f\"Testing\"):\n",
    "    inputs, offsets, targets = [x.to(device) for x in batch]\n",
    "    with torch.no_grad():\n",
    "        output = model(inputs, offsets)\n",
    "        acc += (output.argmax(dim=1) == targets).sum().item()\n",
    "\n",
    "# 输出在测试集上的准确率\n",
    "print(f\"Acc: {acc / len(test_data_loader):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
