{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost\n",
    "CatBoost是俄罗斯搜索引擎巨头Yandex于2017年开源的一款GBDT计算框架，因能够高效处理数据中的类别特征而取名为`CatBoost`(`Categorical Boosting`)。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 机器学习中类别特征的处理方法\n",
    "CatBoost通过对常规的目标变量统计方法添加先验项来改进它们。除此之外CatBoost还考虑使用类别特征的不同组合来增加数据集特征维度。    \n",
    "\n",
    "对于特征取值数目较多的类别特征，一种折中的方法就是将类别数目重新归类，使其降到较少数目再进行one-hot编码。另一种常用的方法是`目标变量统计`（`target statistics, TS`），TS计算每个类别对于目标变量的期望值并将类别特征转换为新的数值特征。CatBoost在常规TS方法上做了改进。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 CatBoost理论基础\n",
    "`CatBoost`算法框架的自身理论特色，包括用于处理类别变量的`目标变量统计`、`特征组合`和`排序提升算法`。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 目标变量统计\n",
    "`CatBoost`算法的设计初衷是为了更好的处理GBDT特征中的`categorical features`。在处理 GBDT特征中的categorical features的时候，最简单的方法是用 categorical feature 对应的标签的平均值来替换。在决策树中，标签平均值将作为节点分裂的标准。这种方法被称为 `Greedy Target-based Statistics` , 简称 `Greedy TS`，用公式来表达就是：   \n",
    "$$ \\hat{x}_{k}^{i} =\\frac{\\sum_{j=1}^{n}\\left [ x_{j,k} =x_{i,k}  \\right ]Y_{i}}{\\sum_{j=1}^{n} \\left [ x_{j,k} =x_{i,k}  \\right ]} $$\n",
    "这种方法有一个显而易见的缺陷，就是通常特征比标签包含更多的信息，如果强行用标签的平均值来表示特征的话，当训练数据集和测试数据集数据结构和分布不一样的时候会出条件偏移问题。\n",
    "\n",
    "一个标准的改进 Greedy TS的方式是添加先验分布项，这样可以减少噪声和低频率类别型数据对于数据分布的影响：\n",
    "$$ \\hat{x}_{k}^{i} =\\frac{\\sum_{j=1}^{p-1}\\left [ x_{\\sigma _{j,k} } =x_{\\sigma _{p,k} }  \\right ]Y_{\\sigma _{j}} + \\alpha p}{\\sum_{j=1}^{p-1} \\left [ x_{\\sigma _{j,k} } =x_{\\sigma _{p,k} }  \\right ]+\\alpha } $$\n",
    "其中p是添加的先验项，α通常是大于0的权重系数。添加先验项是一个普遍做法，针对类别数较少的特征，它可以减少噪声数据。对于回归问题，一般情况下，先验项可取数据集label的均值。对于二分类，先验项是正例的先验概率。利用多个数据集排列也是有效的，但是，如果直接计算可能导致过拟合。\n",
    "\n",
    "CatBoost利用了一个比较新颖的计算叶子节点值的方法，这种方式(`oblivious trees`，对称树)可以避免多个数据集排列中直接计算会出现过拟合的问题。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 特征组合\n",
    "值得注意的是几个类别型特征的任意组合都可视为新的特征。例如，在音乐推荐应用中，我们有两个类别型特征：用户ID和音乐流派。如果有些用户更喜欢摇滚乐，将用户ID和音乐流派转换为数字特征时，根据上述这些信息就会丢失。\n",
    "\n",
    "结合这两个特征就可以解决这个问题，并且可以得到一个新的强大的特征。然而，组合的数量会随着数据集中类别型特征的数量成指数增长，因此不可能在算法中考虑所有组合。\n",
    "\n",
    "为当前树构造新的分割点时，CatBoost会采用贪婪的策略考虑组合。对于树的第一次分割，不考虑任何组合。对于下一个分割，CatBoost将当前树的所有组合、类别型特征与数据集中的所有类别型特征相结合，并将新的组合类别型特征动态地转换为数值型特征。 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 排序提升算法\n",
    "对于学习预测偏移的内容，我提出了两个问题：\n",
    "\n",
    "- 什么是预测偏移？\n",
    "- 用什么办法解决预测偏移问题？\n",
    "\n",
    "预测偏移（`Prediction shift`）是由梯度偏差造成的。在GDBT的每一步迭代中, 损失函数使用相同的数据集求得当前模型的梯度, 然后训练得到基学习器, 但这会导致梯度估计偏差, 进而导致模型产生过拟合的问题。 \n",
    "\n",
    "CatBoost通过采用排序提升 (`Ordered boosting`) 的方式替换传统算法中梯度估计方法，进而减轻梯度估计的偏差，提高模型的泛化能力。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CatBoost`采用对称树作为基分类器，对称意味着在树的同一层，分裂标准相同。对称树具有平衡、不易过拟合、能够大大缩短测试时间的特点。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 CatBoost算法实现\n",
    "作为与XGBoost和LightGBM齐名的Boosting算法，CatBoost有足够优秀的性能指标，尤其是对类别特征的处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                  1       2            3   4                    5   \\\n",
       "0      39          State-gov   77516    Bachelors  13        Never-married   \n",
       "1      50   Self-emp-not-inc   83311    Bachelors  13   Married-civ-spouse   \n",
       "2      38            Private  215646      HS-grad   9             Divorced   \n",
       "3      53            Private  234721         11th   7   Married-civ-spouse   \n",
       "4      28            Private  338409    Bachelors  13   Married-civ-spouse   \n",
       "...    ..                ...     ...          ...  ..                  ...   \n",
       "32556  27            Private  257302   Assoc-acdm  12   Married-civ-spouse   \n",
       "32557  40            Private  154374      HS-grad   9   Married-civ-spouse   \n",
       "32558  58            Private  151910      HS-grad   9              Widowed   \n",
       "32559  22            Private  201490      HS-grad   9        Never-married   \n",
       "32560  52       Self-emp-inc  287927      HS-grad   9   Married-civ-spouse   \n",
       "\n",
       "                       6               7       8        9      10  11  12  \\\n",
       "0            Adm-clerical   Not-in-family   White     Male   2174   0  40   \n",
       "1         Exec-managerial         Husband   White     Male      0   0  13   \n",
       "2       Handlers-cleaners   Not-in-family   White     Male      0   0  40   \n",
       "3       Handlers-cleaners         Husband   Black     Male      0   0  40   \n",
       "4          Prof-specialty            Wife   Black   Female      0   0  40   \n",
       "...                   ...             ...     ...      ...    ...  ..  ..   \n",
       "32556        Tech-support            Wife   White   Female      0   0  38   \n",
       "32557   Machine-op-inspct         Husband   White     Male      0   0  40   \n",
       "32558        Adm-clerical       Unmarried   White   Female      0   0  40   \n",
       "32559        Adm-clerical       Own-child   White     Male      0   0  20   \n",
       "32560     Exec-managerial            Wife   White   Female  15024   0  40   \n",
       "\n",
       "                   13      14  \n",
       "0       United-States   <=50K  \n",
       "1       United-States   <=50K  \n",
       "2       United-States   <=50K  \n",
       "3       United-States   <=50K  \n",
       "4                Cuba   <=50K  \n",
       "...               ...     ...  \n",
       "32556   United-States   <=50K  \n",
       "32557   United-States    >50K  \n",
       "32558   United-States   <=50K  \n",
       "32559   United-States   <=50K  \n",
       "32560   United-States    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./adult.data', header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         <=50K\n",
       "1         <=50K\n",
       "2         <=50K\n",
       "3         <=50K\n",
       "4         <=50K\n",
       "          ...  \n",
       "32556     <=50K\n",
       "32557      >50K\n",
       "32558     <=50K\n",
       "32559     <=50K\n",
       "32560      >50K\n",
       "Name: income, Length: 32561, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race',\n",
    "                'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'] # 变量重命名\n",
    "data['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['income'] = data['income'].astype('category').cat.codes\n",
    "data['income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 274ms\tremaining: 2m 16s\n",
      "1:\ttotal: 337ms\tremaining: 1m 23s\n",
      "2:\ttotal: 384ms\tremaining: 1m 3s\n",
      "3:\ttotal: 434ms\tremaining: 53.8s\n",
      "4:\ttotal: 485ms\tremaining: 48s\n",
      "5:\ttotal: 558ms\tremaining: 45.9s\n",
      "6:\ttotal: 596ms\tremaining: 41.9s\n",
      "7:\ttotal: 642ms\tremaining: 39.5s\n",
      "8:\ttotal: 676ms\tremaining: 36.9s\n",
      "9:\ttotal: 712ms\tremaining: 34.9s\n",
      "10:\ttotal: 748ms\tremaining: 33.3s\n",
      "11:\ttotal: 782ms\tremaining: 31.8s\n",
      "12:\ttotal: 816ms\tremaining: 30.6s\n",
      "13:\ttotal: 854ms\tremaining: 29.6s\n",
      "14:\ttotal: 896ms\tremaining: 29s\n",
      "15:\ttotal: 941ms\tremaining: 28.4s\n",
      "16:\ttotal: 981ms\tremaining: 27.9s\n",
      "17:\ttotal: 1.02s\tremaining: 27.3s\n",
      "18:\ttotal: 1.06s\tremaining: 26.8s\n",
      "19:\ttotal: 1.1s\tremaining: 26.4s\n",
      "20:\ttotal: 1.14s\tremaining: 26s\n",
      "21:\ttotal: 1.18s\tremaining: 25.6s\n",
      "22:\ttotal: 1.22s\tremaining: 25.2s\n",
      "23:\ttotal: 1.25s\tremaining: 24.8s\n",
      "24:\ttotal: 1.28s\tremaining: 24.4s\n",
      "25:\ttotal: 1.32s\tremaining: 24.1s\n",
      "26:\ttotal: 1.36s\tremaining: 23.8s\n",
      "27:\ttotal: 1.39s\tremaining: 23.5s\n",
      "28:\ttotal: 1.43s\tremaining: 23.3s\n",
      "29:\ttotal: 1.47s\tremaining: 23s\n",
      "30:\ttotal: 1.51s\tremaining: 22.8s\n",
      "31:\ttotal: 1.54s\tremaining: 22.6s\n",
      "32:\ttotal: 1.58s\tremaining: 22.3s\n",
      "33:\ttotal: 1.61s\tremaining: 22.1s\n",
      "34:\ttotal: 1.65s\tremaining: 21.9s\n",
      "35:\ttotal: 1.69s\tremaining: 21.7s\n",
      "36:\ttotal: 1.72s\tremaining: 21.5s\n",
      "37:\ttotal: 1.75s\tremaining: 21.3s\n",
      "38:\ttotal: 1.79s\tremaining: 21.1s\n",
      "39:\ttotal: 1.82s\tremaining: 21s\n",
      "40:\ttotal: 1.88s\tremaining: 21s\n",
      "41:\ttotal: 1.91s\tremaining: 20.8s\n",
      "42:\ttotal: 1.95s\tremaining: 20.7s\n",
      "43:\ttotal: 1.98s\tremaining: 20.5s\n",
      "44:\ttotal: 2.01s\tremaining: 20.3s\n",
      "45:\ttotal: 2.04s\tremaining: 20.2s\n",
      "46:\ttotal: 2.08s\tremaining: 20.1s\n",
      "47:\ttotal: 2.11s\tremaining: 19.9s\n",
      "48:\ttotal: 2.15s\tremaining: 19.8s\n",
      "49:\ttotal: 2.18s\tremaining: 19.6s\n",
      "50:\ttotal: 2.21s\tremaining: 19.4s\n",
      "51:\ttotal: 2.24s\tremaining: 19.3s\n",
      "52:\ttotal: 2.28s\tremaining: 19.2s\n",
      "53:\ttotal: 2.32s\tremaining: 19.1s\n",
      "54:\ttotal: 2.36s\tremaining: 19.1s\n",
      "55:\ttotal: 2.4s\tremaining: 19s\n",
      "56:\ttotal: 2.43s\tremaining: 18.9s\n",
      "57:\ttotal: 2.47s\tremaining: 18.8s\n",
      "58:\ttotal: 2.5s\tremaining: 18.7s\n",
      "59:\ttotal: 2.54s\tremaining: 18.6s\n",
      "60:\ttotal: 2.57s\tremaining: 18.5s\n",
      "61:\ttotal: 2.6s\tremaining: 18.4s\n",
      "62:\ttotal: 2.63s\tremaining: 18.3s\n",
      "63:\ttotal: 2.67s\tremaining: 18.2s\n",
      "64:\ttotal: 2.7s\tremaining: 18.1s\n",
      "65:\ttotal: 2.73s\tremaining: 18s\n",
      "66:\ttotal: 2.77s\tremaining: 17.9s\n",
      "67:\ttotal: 2.8s\tremaining: 17.8s\n",
      "68:\ttotal: 2.83s\tremaining: 17.7s\n",
      "69:\ttotal: 2.87s\tremaining: 17.6s\n",
      "70:\ttotal: 2.91s\tremaining: 17.6s\n",
      "71:\ttotal: 2.94s\tremaining: 17.5s\n",
      "72:\ttotal: 2.97s\tremaining: 17.4s\n",
      "73:\ttotal: 3.01s\tremaining: 17.3s\n",
      "74:\ttotal: 3.04s\tremaining: 17.3s\n",
      "75:\ttotal: 3.08s\tremaining: 17.2s\n",
      "76:\ttotal: 3.11s\tremaining: 17.1s\n",
      "77:\ttotal: 3.15s\tremaining: 17s\n",
      "78:\ttotal: 3.18s\tremaining: 16.9s\n",
      "79:\ttotal: 3.21s\tremaining: 16.9s\n",
      "80:\ttotal: 3.25s\tremaining: 16.8s\n",
      "81:\ttotal: 3.28s\tremaining: 16.7s\n",
      "82:\ttotal: 3.31s\tremaining: 16.6s\n",
      "83:\ttotal: 3.34s\tremaining: 16.6s\n",
      "84:\ttotal: 3.38s\tremaining: 16.5s\n",
      "85:\ttotal: 3.41s\tremaining: 16.4s\n",
      "86:\ttotal: 3.44s\tremaining: 16.3s\n",
      "87:\ttotal: 3.48s\tremaining: 16.3s\n",
      "88:\ttotal: 3.51s\tremaining: 16.2s\n",
      "89:\ttotal: 3.55s\tremaining: 16.2s\n",
      "90:\ttotal: 3.58s\tremaining: 16.1s\n",
      "91:\ttotal: 3.62s\tremaining: 16s\n",
      "92:\ttotal: 3.65s\tremaining: 16s\n",
      "93:\ttotal: 3.68s\tremaining: 15.9s\n",
      "94:\ttotal: 3.72s\tremaining: 15.8s\n",
      "95:\ttotal: 3.76s\tremaining: 15.8s\n",
      "96:\ttotal: 3.81s\tremaining: 15.9s\n",
      "97:\ttotal: 3.85s\tremaining: 15.8s\n",
      "98:\ttotal: 3.9s\tremaining: 15.8s\n",
      "99:\ttotal: 3.93s\tremaining: 15.7s\n",
      "100:\ttotal: 3.96s\tremaining: 15.6s\n",
      "101:\ttotal: 3.99s\tremaining: 15.6s\n",
      "102:\ttotal: 4.03s\tremaining: 15.5s\n",
      "103:\ttotal: 4.06s\tremaining: 15.5s\n",
      "104:\ttotal: 4.1s\tremaining: 15.4s\n",
      "105:\ttotal: 4.14s\tremaining: 15.4s\n",
      "106:\ttotal: 4.17s\tremaining: 15.3s\n",
      "107:\ttotal: 4.2s\tremaining: 15.3s\n",
      "108:\ttotal: 4.24s\tremaining: 15.2s\n",
      "109:\ttotal: 4.27s\tremaining: 15.2s\n",
      "110:\ttotal: 4.31s\tremaining: 15.1s\n",
      "111:\ttotal: 4.34s\tremaining: 15s\n",
      "112:\ttotal: 4.38s\tremaining: 15s\n",
      "113:\ttotal: 4.41s\tremaining: 14.9s\n",
      "114:\ttotal: 4.46s\tremaining: 14.9s\n",
      "115:\ttotal: 4.49s\tremaining: 14.9s\n",
      "116:\ttotal: 4.53s\tremaining: 14.8s\n",
      "117:\ttotal: 4.57s\tremaining: 14.8s\n",
      "118:\ttotal: 4.6s\tremaining: 14.7s\n",
      "119:\ttotal: 4.63s\tremaining: 14.7s\n",
      "120:\ttotal: 4.67s\tremaining: 14.6s\n",
      "121:\ttotal: 4.7s\tremaining: 14.6s\n",
      "122:\ttotal: 4.73s\tremaining: 14.5s\n",
      "123:\ttotal: 4.77s\tremaining: 14.5s\n",
      "124:\ttotal: 4.8s\tremaining: 14.4s\n",
      "125:\ttotal: 4.84s\tremaining: 14.4s\n",
      "126:\ttotal: 4.87s\tremaining: 14.3s\n",
      "127:\ttotal: 4.91s\tremaining: 14.3s\n",
      "128:\ttotal: 4.94s\tremaining: 14.2s\n",
      "129:\ttotal: 4.98s\tremaining: 14.2s\n",
      "130:\ttotal: 5.01s\tremaining: 14.1s\n",
      "131:\ttotal: 5.05s\tremaining: 14.1s\n",
      "132:\ttotal: 5.09s\tremaining: 14.1s\n",
      "133:\ttotal: 5.12s\tremaining: 14s\n",
      "134:\ttotal: 5.16s\tremaining: 13.9s\n",
      "135:\ttotal: 5.2s\tremaining: 13.9s\n",
      "136:\ttotal: 5.23s\tremaining: 13.9s\n",
      "137:\ttotal: 5.27s\tremaining: 13.8s\n",
      "138:\ttotal: 5.3s\tremaining: 13.8s\n",
      "139:\ttotal: 5.34s\tremaining: 13.7s\n",
      "140:\ttotal: 5.37s\tremaining: 13.7s\n",
      "141:\ttotal: 5.4s\tremaining: 13.6s\n",
      "142:\ttotal: 5.43s\tremaining: 13.6s\n",
      "143:\ttotal: 5.46s\tremaining: 13.5s\n",
      "144:\ttotal: 5.5s\tremaining: 13.5s\n",
      "145:\ttotal: 5.54s\tremaining: 13.4s\n",
      "146:\ttotal: 5.58s\tremaining: 13.4s\n",
      "147:\ttotal: 5.62s\tremaining: 13.4s\n",
      "148:\ttotal: 5.65s\tremaining: 13.3s\n",
      "149:\ttotal: 5.69s\tremaining: 13.3s\n",
      "150:\ttotal: 5.74s\tremaining: 13.3s\n",
      "151:\ttotal: 5.77s\tremaining: 13.2s\n",
      "152:\ttotal: 5.8s\tremaining: 13.2s\n",
      "153:\ttotal: 5.84s\tremaining: 13.1s\n",
      "154:\ttotal: 5.87s\tremaining: 13.1s\n",
      "155:\ttotal: 5.91s\tremaining: 13s\n",
      "156:\ttotal: 5.94s\tremaining: 13s\n",
      "157:\ttotal: 5.98s\tremaining: 12.9s\n",
      "158:\ttotal: 6.01s\tremaining: 12.9s\n",
      "159:\ttotal: 6.05s\tremaining: 12.9s\n",
      "160:\ttotal: 6.09s\tremaining: 12.8s\n",
      "161:\ttotal: 6.13s\tremaining: 12.8s\n",
      "162:\ttotal: 6.16s\tremaining: 12.7s\n",
      "163:\ttotal: 6.19s\tremaining: 12.7s\n",
      "164:\ttotal: 6.22s\tremaining: 12.6s\n",
      "165:\ttotal: 6.26s\tremaining: 12.6s\n",
      "166:\ttotal: 6.29s\tremaining: 12.5s\n",
      "167:\ttotal: 6.32s\tremaining: 12.5s\n",
      "168:\ttotal: 6.36s\tremaining: 12.4s\n",
      "169:\ttotal: 6.39s\tremaining: 12.4s\n",
      "170:\ttotal: 6.43s\tremaining: 12.4s\n",
      "171:\ttotal: 6.46s\tremaining: 12.3s\n",
      "172:\ttotal: 6.5s\tremaining: 12.3s\n",
      "173:\ttotal: 6.53s\tremaining: 12.2s\n",
      "174:\ttotal: 6.56s\tremaining: 12.2s\n",
      "175:\ttotal: 6.6s\tremaining: 12.1s\n",
      "176:\ttotal: 6.63s\tremaining: 12.1s\n",
      "177:\ttotal: 6.67s\tremaining: 12.1s\n",
      "178:\ttotal: 6.7s\tremaining: 12s\n",
      "179:\ttotal: 6.74s\tremaining: 12s\n",
      "180:\ttotal: 6.77s\tremaining: 11.9s\n",
      "181:\ttotal: 6.8s\tremaining: 11.9s\n",
      "182:\ttotal: 6.85s\tremaining: 11.9s\n",
      "183:\ttotal: 6.89s\tremaining: 11.8s\n",
      "184:\ttotal: 6.92s\tremaining: 11.8s\n",
      "185:\ttotal: 6.96s\tremaining: 11.7s\n",
      "186:\ttotal: 7s\tremaining: 11.7s\n",
      "187:\ttotal: 7.03s\tremaining: 11.7s\n",
      "188:\ttotal: 7.07s\tremaining: 11.6s\n",
      "189:\ttotal: 7.1s\tremaining: 11.6s\n",
      "190:\ttotal: 7.14s\tremaining: 11.5s\n",
      "191:\ttotal: 7.17s\tremaining: 11.5s\n",
      "192:\ttotal: 7.21s\tremaining: 11.5s\n",
      "193:\ttotal: 7.25s\tremaining: 11.4s\n",
      "194:\ttotal: 7.29s\tremaining: 11.4s\n",
      "195:\ttotal: 7.33s\tremaining: 11.4s\n",
      "196:\ttotal: 7.36s\tremaining: 11.3s\n",
      "197:\ttotal: 7.39s\tremaining: 11.3s\n",
      "198:\ttotal: 7.43s\tremaining: 11.2s\n",
      "199:\ttotal: 7.46s\tremaining: 11.2s\n",
      "200:\ttotal: 7.5s\tremaining: 11.2s\n",
      "201:\ttotal: 7.53s\tremaining: 11.1s\n",
      "202:\ttotal: 7.56s\tremaining: 11.1s\n",
      "203:\ttotal: 7.6s\tremaining: 11s\n",
      "204:\ttotal: 7.63s\tremaining: 11s\n",
      "205:\ttotal: 7.67s\tremaining: 10.9s\n",
      "206:\ttotal: 7.71s\tremaining: 10.9s\n",
      "207:\ttotal: 7.74s\tremaining: 10.9s\n",
      "208:\ttotal: 7.77s\tremaining: 10.8s\n",
      "209:\ttotal: 7.81s\tremaining: 10.8s\n",
      "210:\ttotal: 7.84s\tremaining: 10.7s\n",
      "211:\ttotal: 7.88s\tremaining: 10.7s\n",
      "212:\ttotal: 7.91s\tremaining: 10.7s\n",
      "213:\ttotal: 7.95s\tremaining: 10.6s\n",
      "214:\ttotal: 7.99s\tremaining: 10.6s\n",
      "215:\ttotal: 8.02s\tremaining: 10.5s\n",
      "216:\ttotal: 8.05s\tremaining: 10.5s\n",
      "217:\ttotal: 8.09s\tremaining: 10.5s\n",
      "218:\ttotal: 8.13s\tremaining: 10.4s\n",
      "219:\ttotal: 8.16s\tremaining: 10.4s\n",
      "220:\ttotal: 8.19s\tremaining: 10.3s\n",
      "221:\ttotal: 8.23s\tremaining: 10.3s\n",
      "222:\ttotal: 8.27s\tremaining: 10.3s\n",
      "223:\ttotal: 8.3s\tremaining: 10.2s\n",
      "224:\ttotal: 8.34s\tremaining: 10.2s\n",
      "225:\ttotal: 8.38s\tremaining: 10.2s\n",
      "226:\ttotal: 8.41s\tremaining: 10.1s\n",
      "227:\ttotal: 8.44s\tremaining: 10.1s\n",
      "228:\ttotal: 8.48s\tremaining: 10s\n",
      "229:\ttotal: 8.52s\tremaining: 10s\n",
      "230:\ttotal: 8.55s\tremaining: 9.96s\n",
      "231:\ttotal: 8.59s\tremaining: 9.92s\n",
      "232:\ttotal: 8.62s\tremaining: 9.88s\n",
      "233:\ttotal: 8.65s\tremaining: 9.84s\n",
      "234:\ttotal: 8.69s\tremaining: 9.8s\n",
      "235:\ttotal: 8.72s\tremaining: 9.76s\n",
      "236:\ttotal: 8.76s\tremaining: 9.72s\n",
      "237:\ttotal: 8.8s\tremaining: 9.69s\n",
      "238:\ttotal: 8.83s\tremaining: 9.64s\n",
      "239:\ttotal: 8.87s\tremaining: 9.6s\n",
      "240:\ttotal: 8.9s\tremaining: 9.56s\n",
      "241:\ttotal: 8.93s\tremaining: 9.52s\n",
      "242:\ttotal: 8.96s\tremaining: 9.48s\n",
      "243:\ttotal: 9s\tremaining: 9.44s\n",
      "244:\ttotal: 9.03s\tremaining: 9.4s\n",
      "245:\ttotal: 9.07s\tremaining: 9.36s\n",
      "246:\ttotal: 9.1s\tremaining: 9.32s\n",
      "247:\ttotal: 9.14s\tremaining: 9.29s\n",
      "248:\ttotal: 9.17s\tremaining: 9.25s\n",
      "249:\ttotal: 9.21s\tremaining: 9.21s\n",
      "250:\ttotal: 9.24s\tremaining: 9.17s\n",
      "251:\ttotal: 9.28s\tremaining: 9.13s\n",
      "252:\ttotal: 9.31s\tremaining: 9.09s\n",
      "253:\ttotal: 9.35s\tremaining: 9.05s\n",
      "254:\ttotal: 9.38s\tremaining: 9.01s\n",
      "255:\ttotal: 9.41s\tremaining: 8.97s\n",
      "256:\ttotal: 9.44s\tremaining: 8.93s\n",
      "257:\ttotal: 9.49s\tremaining: 8.9s\n",
      "258:\ttotal: 9.52s\tremaining: 8.86s\n",
      "259:\ttotal: 9.56s\tremaining: 8.82s\n",
      "260:\ttotal: 9.59s\tremaining: 8.79s\n",
      "261:\ttotal: 9.63s\tremaining: 8.75s\n",
      "262:\ttotal: 9.66s\tremaining: 8.71s\n",
      "263:\ttotal: 9.7s\tremaining: 8.67s\n",
      "264:\ttotal: 9.73s\tremaining: 8.63s\n",
      "265:\ttotal: 9.77s\tremaining: 8.6s\n",
      "266:\ttotal: 9.81s\tremaining: 8.56s\n",
      "267:\ttotal: 9.84s\tremaining: 8.52s\n",
      "268:\ttotal: 9.87s\tremaining: 8.48s\n",
      "269:\ttotal: 9.91s\tremaining: 8.44s\n",
      "270:\ttotal: 9.94s\tremaining: 8.4s\n",
      "271:\ttotal: 9.98s\tremaining: 8.37s\n",
      "272:\ttotal: 10s\tremaining: 8.34s\n",
      "273:\ttotal: 10.1s\tremaining: 8.3s\n",
      "274:\ttotal: 10.1s\tremaining: 8.26s\n",
      "275:\ttotal: 10.1s\tremaining: 8.22s\n",
      "276:\ttotal: 10.2s\tremaining: 8.18s\n",
      "277:\ttotal: 10.2s\tremaining: 8.14s\n",
      "278:\ttotal: 10.2s\tremaining: 8.1s\n",
      "279:\ttotal: 10.3s\tremaining: 8.06s\n",
      "280:\ttotal: 10.3s\tremaining: 8.03s\n",
      "281:\ttotal: 10.3s\tremaining: 7.99s\n",
      "282:\ttotal: 10.4s\tremaining: 7.95s\n",
      "283:\ttotal: 10.4s\tremaining: 7.92s\n",
      "284:\ttotal: 10.4s\tremaining: 7.88s\n",
      "285:\ttotal: 10.5s\tremaining: 7.84s\n",
      "286:\ttotal: 10.5s\tremaining: 7.81s\n",
      "287:\ttotal: 10.6s\tremaining: 7.77s\n",
      "288:\ttotal: 10.6s\tremaining: 7.74s\n",
      "289:\ttotal: 10.6s\tremaining: 7.71s\n",
      "290:\ttotal: 10.7s\tremaining: 7.67s\n",
      "291:\ttotal: 10.7s\tremaining: 7.63s\n",
      "292:\ttotal: 10.8s\tremaining: 7.59s\n",
      "293:\ttotal: 10.8s\tremaining: 7.56s\n",
      "294:\ttotal: 10.8s\tremaining: 7.52s\n",
      "295:\ttotal: 10.9s\tremaining: 7.48s\n",
      "296:\ttotal: 10.9s\tremaining: 7.44s\n",
      "297:\ttotal: 10.9s\tremaining: 7.4s\n",
      "298:\ttotal: 11s\tremaining: 7.37s\n",
      "299:\ttotal: 11s\tremaining: 7.33s\n",
      "300:\ttotal: 11s\tremaining: 7.29s\n",
      "301:\ttotal: 11.1s\tremaining: 7.25s\n",
      "302:\ttotal: 11.1s\tremaining: 7.21s\n",
      "303:\ttotal: 11.1s\tremaining: 7.17s\n",
      "304:\ttotal: 11.2s\tremaining: 7.14s\n",
      "305:\ttotal: 11.2s\tremaining: 7.1s\n",
      "306:\ttotal: 11.2s\tremaining: 7.06s\n",
      "307:\ttotal: 11.3s\tremaining: 7.03s\n",
      "308:\ttotal: 11.3s\tremaining: 7s\n",
      "309:\ttotal: 11.4s\tremaining: 6.96s\n",
      "310:\ttotal: 11.4s\tremaining: 6.92s\n",
      "311:\ttotal: 11.4s\tremaining: 6.88s\n",
      "312:\ttotal: 11.5s\tremaining: 6.85s\n",
      "313:\ttotal: 11.5s\tremaining: 6.81s\n",
      "314:\ttotal: 11.5s\tremaining: 6.78s\n",
      "315:\ttotal: 11.6s\tremaining: 6.74s\n",
      "316:\ttotal: 11.6s\tremaining: 6.71s\n",
      "317:\ttotal: 11.6s\tremaining: 6.67s\n",
      "318:\ttotal: 11.7s\tremaining: 6.63s\n",
      "319:\ttotal: 11.7s\tremaining: 6.59s\n",
      "320:\ttotal: 11.8s\tremaining: 6.55s\n",
      "321:\ttotal: 11.8s\tremaining: 6.52s\n",
      "322:\ttotal: 11.8s\tremaining: 6.48s\n",
      "323:\ttotal: 11.9s\tremaining: 6.45s\n",
      "324:\ttotal: 11.9s\tremaining: 6.41s\n",
      "325:\ttotal: 11.9s\tremaining: 6.38s\n",
      "326:\ttotal: 12s\tremaining: 6.34s\n",
      "327:\ttotal: 12s\tremaining: 6.3s\n",
      "328:\ttotal: 12.1s\tremaining: 6.27s\n",
      "329:\ttotal: 12.1s\tremaining: 6.23s\n",
      "330:\ttotal: 12.1s\tremaining: 6.2s\n",
      "331:\ttotal: 12.2s\tremaining: 6.16s\n",
      "332:\ttotal: 12.2s\tremaining: 6.12s\n",
      "333:\ttotal: 12.2s\tremaining: 6.08s\n",
      "334:\ttotal: 12.3s\tremaining: 6.04s\n",
      "335:\ttotal: 12.3s\tremaining: 6.01s\n",
      "336:\ttotal: 12.3s\tremaining: 5.97s\n",
      "337:\ttotal: 12.4s\tremaining: 5.93s\n",
      "338:\ttotal: 12.4s\tremaining: 5.89s\n",
      "339:\ttotal: 12.4s\tremaining: 5.86s\n",
      "340:\ttotal: 12.5s\tremaining: 5.82s\n",
      "341:\ttotal: 12.5s\tremaining: 5.78s\n",
      "342:\ttotal: 12.6s\tremaining: 5.74s\n",
      "343:\ttotal: 12.6s\tremaining: 5.71s\n",
      "344:\ttotal: 12.6s\tremaining: 5.67s\n",
      "345:\ttotal: 12.7s\tremaining: 5.63s\n",
      "346:\ttotal: 12.7s\tremaining: 5.6s\n",
      "347:\ttotal: 12.7s\tremaining: 5.56s\n",
      "348:\ttotal: 12.8s\tremaining: 5.52s\n",
      "349:\ttotal: 12.8s\tremaining: 5.48s\n",
      "350:\ttotal: 12.8s\tremaining: 5.45s\n",
      "351:\ttotal: 12.9s\tremaining: 5.41s\n",
      "352:\ttotal: 12.9s\tremaining: 5.37s\n",
      "353:\ttotal: 12.9s\tremaining: 5.33s\n",
      "354:\ttotal: 13s\tremaining: 5.3s\n",
      "355:\ttotal: 13s\tremaining: 5.26s\n",
      "356:\ttotal: 13s\tremaining: 5.22s\n",
      "357:\ttotal: 13.1s\tremaining: 5.18s\n",
      "358:\ttotal: 13.1s\tremaining: 5.15s\n",
      "359:\ttotal: 13.1s\tremaining: 5.11s\n",
      "360:\ttotal: 13.2s\tremaining: 5.07s\n",
      "361:\ttotal: 13.2s\tremaining: 5.04s\n",
      "362:\ttotal: 13.2s\tremaining: 5s\n",
      "363:\ttotal: 13.3s\tremaining: 4.96s\n",
      "364:\ttotal: 13.3s\tremaining: 4.92s\n",
      "365:\ttotal: 13.3s\tremaining: 4.88s\n",
      "366:\ttotal: 13.4s\tremaining: 4.84s\n",
      "367:\ttotal: 13.4s\tremaining: 4.81s\n",
      "368:\ttotal: 13.4s\tremaining: 4.77s\n",
      "369:\ttotal: 13.5s\tremaining: 4.74s\n",
      "370:\ttotal: 13.5s\tremaining: 4.7s\n",
      "371:\ttotal: 13.6s\tremaining: 4.66s\n",
      "372:\ttotal: 13.6s\tremaining: 4.63s\n",
      "373:\ttotal: 13.6s\tremaining: 4.59s\n",
      "374:\ttotal: 13.7s\tremaining: 4.55s\n",
      "375:\ttotal: 13.7s\tremaining: 4.52s\n",
      "376:\ttotal: 13.7s\tremaining: 4.48s\n",
      "377:\ttotal: 13.8s\tremaining: 4.44s\n",
      "378:\ttotal: 13.8s\tremaining: 4.4s\n",
      "379:\ttotal: 13.8s\tremaining: 4.36s\n",
      "380:\ttotal: 13.9s\tremaining: 4.33s\n",
      "381:\ttotal: 13.9s\tremaining: 4.29s\n",
      "382:\ttotal: 13.9s\tremaining: 4.25s\n",
      "383:\ttotal: 14s\tremaining: 4.22s\n",
      "384:\ttotal: 14s\tremaining: 4.18s\n",
      "385:\ttotal: 14s\tremaining: 4.14s\n",
      "386:\ttotal: 14.1s\tremaining: 4.11s\n",
      "387:\ttotal: 14.1s\tremaining: 4.07s\n",
      "388:\ttotal: 14.2s\tremaining: 4.04s\n",
      "389:\ttotal: 14.2s\tremaining: 4s\n",
      "390:\ttotal: 14.2s\tremaining: 3.96s\n",
      "391:\ttotal: 14.3s\tremaining: 3.93s\n",
      "392:\ttotal: 14.3s\tremaining: 3.89s\n",
      "393:\ttotal: 14.3s\tremaining: 3.85s\n",
      "394:\ttotal: 14.4s\tremaining: 3.81s\n",
      "395:\ttotal: 14.4s\tremaining: 3.78s\n",
      "396:\ttotal: 14.4s\tremaining: 3.74s\n",
      "397:\ttotal: 14.5s\tremaining: 3.71s\n",
      "398:\ttotal: 14.5s\tremaining: 3.67s\n",
      "399:\ttotal: 14.5s\tremaining: 3.63s\n",
      "400:\ttotal: 14.6s\tremaining: 3.59s\n",
      "401:\ttotal: 14.6s\tremaining: 3.56s\n",
      "402:\ttotal: 14.6s\tremaining: 3.52s\n",
      "403:\ttotal: 14.7s\tremaining: 3.48s\n",
      "404:\ttotal: 14.7s\tremaining: 3.45s\n",
      "405:\ttotal: 14.7s\tremaining: 3.41s\n",
      "406:\ttotal: 14.8s\tremaining: 3.37s\n",
      "407:\ttotal: 14.8s\tremaining: 3.34s\n",
      "408:\ttotal: 14.8s\tremaining: 3.3s\n",
      "409:\ttotal: 14.9s\tremaining: 3.27s\n",
      "410:\ttotal: 14.9s\tremaining: 3.23s\n",
      "411:\ttotal: 14.9s\tremaining: 3.19s\n",
      "412:\ttotal: 15s\tremaining: 3.16s\n",
      "413:\ttotal: 15s\tremaining: 3.12s\n",
      "414:\ttotal: 15.1s\tremaining: 3.08s\n",
      "415:\ttotal: 15.1s\tremaining: 3.05s\n",
      "416:\ttotal: 15.1s\tremaining: 3.01s\n",
      "417:\ttotal: 15.2s\tremaining: 2.97s\n",
      "418:\ttotal: 15.2s\tremaining: 2.94s\n",
      "419:\ttotal: 15.2s\tremaining: 2.9s\n",
      "420:\ttotal: 15.3s\tremaining: 2.86s\n",
      "421:\ttotal: 15.3s\tremaining: 2.83s\n",
      "422:\ttotal: 15.3s\tremaining: 2.79s\n",
      "423:\ttotal: 15.3s\tremaining: 2.75s\n",
      "424:\ttotal: 15.4s\tremaining: 2.71s\n",
      "425:\ttotal: 15.4s\tremaining: 2.68s\n",
      "426:\ttotal: 15.5s\tremaining: 2.64s\n",
      "427:\ttotal: 15.5s\tremaining: 2.6s\n",
      "428:\ttotal: 15.5s\tremaining: 2.57s\n",
      "429:\ttotal: 15.6s\tremaining: 2.53s\n",
      "430:\ttotal: 15.6s\tremaining: 2.5s\n",
      "431:\ttotal: 15.6s\tremaining: 2.46s\n",
      "432:\ttotal: 15.7s\tremaining: 2.42s\n",
      "433:\ttotal: 15.7s\tremaining: 2.39s\n",
      "434:\ttotal: 15.7s\tremaining: 2.35s\n",
      "435:\ttotal: 15.8s\tremaining: 2.31s\n",
      "436:\ttotal: 15.8s\tremaining: 2.28s\n",
      "437:\ttotal: 15.8s\tremaining: 2.24s\n",
      "438:\ttotal: 15.9s\tremaining: 2.21s\n",
      "439:\ttotal: 15.9s\tremaining: 2.17s\n",
      "440:\ttotal: 15.9s\tremaining: 2.13s\n",
      "441:\ttotal: 16s\tremaining: 2.1s\n",
      "442:\ttotal: 16s\tremaining: 2.06s\n",
      "443:\ttotal: 16.1s\tremaining: 2.03s\n",
      "444:\ttotal: 16.1s\tremaining: 1.99s\n",
      "445:\ttotal: 16.1s\tremaining: 1.95s\n",
      "446:\ttotal: 16.2s\tremaining: 1.92s\n",
      "447:\ttotal: 16.2s\tremaining: 1.88s\n",
      "448:\ttotal: 16.2s\tremaining: 1.84s\n",
      "449:\ttotal: 16.3s\tremaining: 1.81s\n",
      "450:\ttotal: 16.3s\tremaining: 1.77s\n",
      "451:\ttotal: 16.4s\tremaining: 1.74s\n",
      "452:\ttotal: 16.4s\tremaining: 1.7s\n",
      "453:\ttotal: 16.4s\tremaining: 1.67s\n",
      "454:\ttotal: 16.5s\tremaining: 1.63s\n",
      "455:\ttotal: 16.5s\tremaining: 1.59s\n",
      "456:\ttotal: 16.5s\tremaining: 1.56s\n",
      "457:\ttotal: 16.6s\tremaining: 1.52s\n",
      "458:\ttotal: 16.6s\tremaining: 1.48s\n",
      "459:\ttotal: 16.7s\tremaining: 1.45s\n",
      "460:\ttotal: 16.7s\tremaining: 1.41s\n",
      "461:\ttotal: 16.7s\tremaining: 1.38s\n",
      "462:\ttotal: 16.8s\tremaining: 1.34s\n",
      "463:\ttotal: 16.8s\tremaining: 1.3s\n",
      "464:\ttotal: 16.8s\tremaining: 1.27s\n",
      "465:\ttotal: 16.9s\tremaining: 1.23s\n",
      "466:\ttotal: 16.9s\tremaining: 1.19s\n",
      "467:\ttotal: 16.9s\tremaining: 1.16s\n",
      "468:\ttotal: 17s\tremaining: 1.12s\n",
      "469:\ttotal: 17s\tremaining: 1.08s\n",
      "470:\ttotal: 17s\tremaining: 1.05s\n",
      "471:\ttotal: 17.1s\tremaining: 1.01s\n",
      "472:\ttotal: 17.1s\tremaining: 977ms\n",
      "473:\ttotal: 17.2s\tremaining: 941ms\n",
      "474:\ttotal: 17.2s\tremaining: 905ms\n",
      "475:\ttotal: 17.2s\tremaining: 868ms\n",
      "476:\ttotal: 17.3s\tremaining: 832ms\n",
      "477:\ttotal: 17.3s\tremaining: 796ms\n",
      "478:\ttotal: 17.3s\tremaining: 760ms\n",
      "479:\ttotal: 17.4s\tremaining: 724ms\n",
      "480:\ttotal: 17.4s\tremaining: 687ms\n",
      "481:\ttotal: 17.4s\tremaining: 651ms\n",
      "482:\ttotal: 17.5s\tremaining: 615ms\n",
      "483:\ttotal: 17.5s\tremaining: 578ms\n",
      "484:\ttotal: 17.5s\tremaining: 543ms\n",
      "485:\ttotal: 17.6s\tremaining: 507ms\n",
      "486:\ttotal: 17.6s\tremaining: 470ms\n",
      "487:\ttotal: 17.7s\tremaining: 434ms\n",
      "488:\ttotal: 17.7s\tremaining: 398ms\n",
      "489:\ttotal: 17.7s\tremaining: 362ms\n",
      "490:\ttotal: 17.8s\tremaining: 326ms\n",
      "491:\ttotal: 17.8s\tremaining: 290ms\n",
      "492:\ttotal: 17.9s\tremaining: 253ms\n",
      "493:\ttotal: 17.9s\tremaining: 217ms\n",
      "494:\ttotal: 17.9s\tremaining: 181ms\n",
      "495:\ttotal: 18s\tremaining: 145ms\n",
      "496:\ttotal: 18s\tremaining: 109ms\n",
      "497:\ttotal: 18s\tremaining: 72.4ms\n",
      "498:\ttotal: 18.1s\tremaining: 36.2ms\n",
      "499:\ttotal: 18.1s\tremaining: 0us\n",
      "0.8721465861398301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import catboost as cb\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(['income'], axis=1), data['income'], random_state=10, test_size=0.3)\n",
    "clf = cb.CatBoostClassifier(eval_metric='AUC', depth=4, iterations=500, l2_leaf_reg=1, learning_rate=0.1)\n",
    "cat_features_index = [1, 3, 5, 6, 7, 8, 9, 13] # 设置分类特征的索引，以便 CatBoost 能够正确地识别这些特征\n",
    "clf.fit(X_train, y_train, cat_features=cat_features_index)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
