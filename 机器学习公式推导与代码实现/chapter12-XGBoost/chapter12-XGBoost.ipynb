{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "从算法精度、速度和泛化能力等性能指标来看`GBDT`，仍然有较大的优化空间。`XGBoost`是一种基于`GBDT`的顶级梯度提升模型。相较于`GBDT`，`XGBoost`的最大特性在于对损失函数展开到二阶导数，使得梯度提升树模型更能逼近其真实损失。    \n",
    "`XGBoost`全称`eXtreme Gradient Boosting`，即极限梯度提升树，由陈天奇在其论文`XGBoost:A Scalable Tree Boosting System`中提出。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 XGBoost介绍"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost本质上仍属于GBDT算法，但在`算法精度`、`速度`和`泛化能力`上均要优于传统的GBDT算法。从算法精度上来看，XGBoost通过`将损失函数展开到二阶导数`，使得其更能逼近真是损失；从算法速度上来看，XGBoost使用了`加权分位数sketch`和`稀疏感知算法`这两个技巧，通过`缓存优化`和`模型并行`来提高算法速度；从算法泛化能力上来看，通过`对损失函数加入正则化项`、加性模型中`设置缩减率`和`列抽样`等方法，来防止模型过拟合。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 XGBoost算法实现\n",
    "相较于GBDT，XGBoost的主要变化在于`损失函数二阶导数`、`信息增益计算`和`叶子结点得分计算`等方面，与上一章GBDT使用回归树不同，本章以分类树为例。   \n",
    "整个实现过程概括为：从损失函数出发，进行二阶泰勒展开并重新定义一棵决策树，通过对叶子结点分组得到最终的损失函数形式，最后求得最优点和最优取值，并得到叶子结点的分裂标准。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cart import BinaryDecisionTree\n",
    "import numpy as np\n",
    "\n",
    "# XGBoost单棵树类\n",
    "class XGBoost_Single_Tree(BinaryDecisionTree):\n",
    "\n",
    "    def node_split(self, y): # 结点分裂方法\n",
    "        feature = int(np.shape(y)[1]/2) # 中间特征所在列\n",
    "        y_true, y_pred = y[:, :feature], y[:, feature:] # 左子树为真实值，右子树为预测值\n",
    "        return y_true, y_pred\n",
    "\n",
    "    def gain(self, y, y_pred): # 信息增益计算方法\n",
    "        Gradient = np.power((y * self.loss.gradient(y, y_pred)).sum(), 2) # 梯度计算（一阶导数）\n",
    "        Hessian = self.loss.hess(y, y_pred).sum() # 黑塞矩阵（二阶导数）\n",
    "        return 0.5 * (Gradient / Hessian)\n",
    "\n",
    "    def gain_xgb(self, y, y1, y2): # 树分裂增益计算-式（12-22）\n",
    "        y_true, y_pred = self.node_split(y)\n",
    "        y1, y1_pred = self.node_split(y1)\n",
    "        y2, y2_pred = self.node_split(y2)\n",
    "        true_gain = self.gain(y1, y1_pred)\n",
    "        false_gain = self.gain(y2, y2_pred)\n",
    "        gain = self.gain(y_true, y_pred)\n",
    "        return true_gain + false_gain - gain\n",
    "\n",
    "    def leaf_weight(self, y): # 计算叶子结点最优权重 w*\n",
    "        y_true, y_pred = self.node_split(y)\n",
    "        gradient = np.sum(y_true * self.loss.gradient(y_true, y_pred), axis=0) # 梯度计算\n",
    "        hessian = np.sum(self.loss.hess(y_true, y_pred), axis=0) # 黑塞矩阵计算\n",
    "        leaf_weight = gradient / hessian\n",
    "        return leaf_weight\n",
    "\n",
    "    # 树拟合方法\n",
    "    def fit(self, X, y):\n",
    "        # 信息增益和叶子节点得分计算都用到了损失函数二阶导数信息\n",
    "        self.impurity_calculation = self.gain_xgb\n",
    "        self._leaf_value_calculation = self.leaf_weight\n",
    "        super(XGBoost_Single_Tree, self).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost分类损失函数\n",
    "class Sigmoid: # 定义Sigmoid类\n",
    "    def __call__(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return self.__call__(x) * (1 - self.__call__(x))\n",
    "\n",
    "# 定义logit损失\n",
    "class LogisticLoss:\n",
    "    def __init__(self):\n",
    "        sigmoid = Sigmoid()\n",
    "        self._func = sigmoid\n",
    "        self._grad = sigmoid.gradient\n",
    "    \n",
    "    # 定义Logit损失\n",
    "    def loss(self, y, y_pred):\n",
    "        y_pred = np.clip(y_pred, 1e-15, 1, 1e-15) # 截断函数\n",
    "        p = self._func(y_pred)\n",
    "        return y * np.log(p) + (1 - y) * np.log(1 - p)\n",
    "    \n",
    "    # 定义一阶梯度\n",
    "    def gradient(self, y, y_pred):\n",
    "        p = self._func(y_pred)\n",
    "        return -(y - p)\n",
    "    \n",
    "    # 定义二阶梯度\n",
    "    def hess(self, y, y_pred):\n",
    "        p = self._func(y_pred)\n",
    "        return p * (1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import cat_label_convert\n",
    "\n",
    "# XGBoost模型\n",
    "class XGBoost:\n",
    "    def __init__(self, n_estimators=300, learning_rate=0.001, min_samples_split=2, min_gini_impurity=999, max_depth=2):\n",
    "        self.n_estimators = n_estimators # 树的棵数\n",
    "        self.learning_rate = learning_rate # 学习率\n",
    "        self.min_samples_split = min_samples_split # 结点分裂最小样本数\n",
    "        self.min_gini_impurity = min_gini_impurity # 结点最小基尼不纯度\n",
    "        self.max_depth = max_depth # 树最大深度\n",
    "        self.loss = LogisticLoss() # 用于分类的对数损失，回归任务定义平方损失\n",
    "        self.estimators = [] # 初始化分类树列表\n",
    "\n",
    "        for _ in range(n_estimators): # 遍历构造每一棵决策树\n",
    "            tree = XGBoost_Single_Tree(\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                min_gini_impurity=self.min_gini_impurity,\n",
    "                max_depth = max_depth,\n",
    "                loss = self.loss\n",
    "            )\n",
    "            self.estimators.append(tree)\n",
    "\n",
    "    def fit(self, X, y): # XGBoost拟合方法\n",
    "        y = cat_label_convert(y) # one-hot\n",
    "        y_pred = np.zeros(np.shape(y))\n",
    "        for i in range(self.n_estimators): # 拟合每一棵树后将结果累加\n",
    "            estimator = self.estimators[i]\n",
    "            y_true_pred = np.concatenate((y, y_pred), axis=1)\n",
    "            estimator.fit(X, y_true_pred)\n",
    "            iter_pred = estimator.predict(X)\n",
    "            y_pred -= np.multiply(self.learning_rate, iter_pred)\n",
    "\n",
    "    def predict(self, X): # XGBoost预测方法\n",
    "        y_pred = None\n",
    "        for estimator in self.estimators: # 遍历预测\n",
    "            iter_pred = estimator.predict(X)\n",
    "            if y_pred is None:\n",
    "                y_pred = np.zeros_like(iter_pred)\n",
    "            y_pred -= np.multiply(self.learning_rate, iter_pred)\n",
    "        y_pred = np.exp(y_pred) / np.sum(np.exp(y_pred), axis=1, keepdims=True)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Jiawen9-s-Reading-Notes\\机器学习公式推导与代码实现\\chapter12-XGBoost\\utils.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array([X_left, X_right])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# XGBoost测试\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets # 导入鸢尾花数据集\n",
    "data = datasets.load_iris()\n",
    "X, y = data.data, data.target # 获取输入输出\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)  # 数据集划分\n",
    "clf = XGBoost() # 创建xgboost分类器\n",
    "clf.fit(X_train, y_train) # 模型拟合\n",
    "y_pred = clf.predict(X_test) # 模型预测\n",
    "accuracy = accuracy_score(y_test, y_pred) # 准确率评估\n",
    "print (\"Accuracy: \", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 XGBoost原生库示例\n",
    "XGBoost的作者陈天奇也提供了XGBoost原生的工业级官方库xgboost。   \n",
    "首先需要指定xgboost模型训练的各种参数，包括提升树类型、任务类型、类别数量和树的最大深度等，然后将原始数据类型转换为xgboost的DMatrix数据类型，接着进行模型训练和预测，最后评估分类准确率，并绘制特征重要性图，可视化地呈现每个特征在模型中的重要性评分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance # 导入绘制特征重要性模块函数\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 设置模型参数\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3,\n",
    "    'gamma': 0.1,\n",
    "    'max_depth': 2,\n",
    "    'lambda': 2,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'min_child_weight': 3,\n",
    "    'eta': 0.001,\n",
    "    'seed': 1000,\n",
    "    'nthread': 4,\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train) # 转换为xgb数据集格式Dmatrix\n",
    "num_rounds = 200 # 树的棵数\n",
    "model = xgb.train(params, dtrain, num_rounds)\n",
    "y_pred = model.predict(xgb.DMatrix(X_test)) # 对测试集进行验证\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
